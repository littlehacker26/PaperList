# Content
- [量子与复数网络](#量子与复数网络)
- [量子应用](#量子应用)
- [对话检索](#对话检索)
- [多模态对话情感分类](#多模态对话情感分类)
- [多模态](#多模态)
- [对话任务](#对话任务)
- [热点知识](#热点知识)
- [对话结构](#对话结构)
- [对话生成](#对话生成)
- [其他](#其他)

# 基础理论
  - NIPS2019, [Distributional Reinforcement Learning for Energy-Based Sequential Models](https://arxiv.org/pdf/1912.08517.pdf)
  - ICLR workshop 2021,[ON FEATURE DIVERSITY IN ENERGY-BASED MODELS](https://openreview.net/pdf?id=ks3Q08yy66r)


# 量子与复数网络
  - IRLR2020, [Benyou Wang, Donghao Zhao, Christina Lioma, Qiuchi Li, Peng Zhang, Jakob Grue Simonsen:Encoding word order in complex embeddings.](https://iclr.cc/virtual_2020/poster_Hke-WTVtwr.html)  & [note](./note/2020_09_25.md)
  - IRLR2020,[Complex-Valued Neural Networks for Privacy Protection](https://www.researchgate.net/publication/330701041_Complex-Valued_Neural_Networks_for_Privacy_Protection)&[note](./note/2020_10.md)
  - IRLR2018,[Deep Complex Network](https://arxiv.org/pdf/1705.09792.pdf)&[note](./note/2020_10.md)
  - NIPS2016,[Unitary Evolution Recurrent Neural Networks](https://arxiv.org/pdf/1511.06464.pdf)
  - NIPS2016,[Full-Capacity Unitary Recurrent Neural Networks](https://dl.acm.org/doi/pdf/10.5555/3157382.3157643)
  - ICLR 2018,[KRONECKER RECURRENT UNITS](https://openreview.net/pdf?id=SyR6Ul1Pf)

# 对话任务
  -  ACL2020,[A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking](https://www.aclweb.org/anthology/2020.acl-main.563/) &[note](.note//2020_10.md)
  - EMNLP2020,[Group-wise Contrastive Learning for Neural Dialogue Generation](https://arxiv.org/abs/2009.07543) &[note](.note//2020_11.md)
  - EMNLP2020,[Multi-turn Response Selection using Dialogue Dependency Relations](https://arxiv.org/abs/2010.01502)
  - EMNLP2020,[Structured Attention for Unsupervised Dialogue Structure Induction](https://www.aclweb.org/anthology/2020.emnlp-main.148/)&[note](./note/2020_11.md)
  - AAAI2019,[A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues](https://arxiv.org/pdf/1812.00176.pdf)&[note](./note/2020_11.md)
  - AAAI2020,[Who Did They Respond to? Conversation Structure Modeling Using Masked Hierarchical Transformer](https://arxiv.org/abs/1911.10666)&[note]()
  - ACL2020,[Towards Emotion-aided Multi-modal Dialogue Act Classification](https://www.aclweb.org/anthology/2020.acl-main.402/)

# 量子应用
  - AAAI2021,[Quantum-inspired Neural Network for Conversational Emotion Recognition]()


# 对话检索
  - SIGIR2020,[Few-Shot Generative Conversational Query Rewriting](https://www.microsoft.com/en-us/research/publication/few-shot-generative-conversational-query-rewriting/) & [note](./note/2020_09.md)
  - WWWW2020, [Leading Conversational Search by Suggesting Useful Questions.](www.baidu.com)

# 对话结构
  - AAAI2018,[Addressee and Response Selection in Multi-Party Conversations with Speaker Interaction RNNs](https://arxiv.org/pdf/1709.04005.pdf)&[note]()
  - ACL2016,[Addressee and Response Selection for Multi-Party Conversation](https://www.aclweb.org/anthology/D16-1231/)&[note]()
  - EMNLP 2019,[Who Is Speaking to Whom? Learning to Identify Utterance Addressee in Multi-Party Conversations](https://www.aclweb.org/anthology/D19-1199/)&[note]()
  - Arixiv2020,[Online Conversation Disentanglement with Pointer Networks](https://arxiv.org/pdf/2010.11080.pdf)


# 对话生成
- CIKM2020,[Ranking Enhanced Dialogue Generation](https://arxiv.org/pdf/2008.05640.pdf )




# 多模态对话情感分类
 - IEEE Trans on Affective Computing,2020. [Adapted Dynamic Memory Network for Emotion Recognition in Conversation](https://ieeexplore.ieee.org/abstract/document/9128015/) &[note](./note/2020_09.md)
 - AAAI2020, [Real-Time Emotion Recognition via Attention Gated Hierarchical Memory Network](https://arxiv.org/pdf/1911.09075.pdf)&[note](./note/2020_09.md)
 - Arxiv 2020,[Multi-Task Learning with Auxiliary Speaker Identification for ConversationalEmotion Recognition](https://arxiv.org/abs/2003.01478)&[note]("./note/2020_10.md")
 - EMMLP,2019, [DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation]() [&note](./note/2020_10.md)
 - Arixiv,2019,[PT-CoDE: Pre-trained Context-Dependent Encoder for Utterance-level Emotion Recognition](https://arxiv.org/pdf/1910.08916.pdf) &[note](./note/2020_10.md)
 - AAAI,2020,[Sentiment Classification in Customer Service Dialogue with Topic-Aware Multi-Task Learning](https://ojs.aaai.org//index.php/AAAI/article/view/6454)&[note](./note/2020_10.md)
 - arxiv 2020,[Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations](https://arxiv.org/pdf/1909.10681.pdf),&[note](./note/2020_10.md)
 - EMNLP 2020,[COSMIC: COmmonSense knowledge for eMotion Identification in Conversations](https://arxiv.org/abs/2010.02795),&[note](./note/2020_11.md)
 - AAAI 2021,[DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition](https://arxiv.org/pdf/2012.08695.pdf)
 - Arixiv,2020,[A Hierarchical Transformer with Speaker Modeling for Emotion Recognition in Conversation](https://arxiv.org/pdf/2012.14781.pdf)


# 多模态
- AAAI 2019,[Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors](https://www.aaai.org/ojs/index.php/AAAI/article/view/4706) &[note]("./note/2020_10.md")
- ACL 2019,[Multimodal Transformer for Unaligned Multimodal Language Sequences](https://arxiv.org/pdf/1906.00295.pdf) &[note](./note/2020_10.md)
- AAAI,2019,[Found in Translation:Learning Robust Joint Representations by Cyclic Translations Between Modalities](https://arxiv.org/pdf/1812.07809.pdf)&[note](./note/2020_10.md)


# 热点知识
- Arixiv 2020, [SUPERVISED CONTRASTIVE LEARNING FOR PRETRAINED LANGUAGE MODEL F INE-TUNING](https://arxiv.org/abs/2011.01403),&[note]()
- Arixiv 2020,[Neural Passage Retrieval with Improved Negative Contrast](https://arxiv.org/pdf/2010.12523.pdf)

# 可控文本生成
- ICLR2020,[Plug and Play Language Models: A Simple Approach to Controlled Text Generation](https://arxiv.org/abs/1912.02164)
- ICLR2021,[A DISTRIBUTIONAL APPROACH TO CONTROLLED TEXT GENERATION](https://openreview.net/pdf?id=jWkw45-9AbL)
- Arixiv,[ Controllable Generation from Pre-trained Language Models via Inverse Prompting](https://arxiv.org/pdf/2103.10685.pdf)
- arixiv,[Plug-and-Blend: A Framework for Controllable Story Generation with Blended Control Codes](https://arxiv.org/pdf/2104.04039.pdf)
- arixiv 2021,[Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/abs/2101.00190)
- ICLR,2021, [COCON: A SELF-SUPERVISED APPROACH FOR CONTROLLED TEXT GENERATION](https://arxiv.org/pdf/2006.03535.pdf)
- ICLR,2020.[GEDI: GENERATIVE DISCRIMINATOR GUIDED SEQUENCE GENERATION](https://arxiv.org/pdf/2009.06367.pdf)
- ICLR,2019.[CTRL: A CONDITIONAL TRANSFORMER LANGUAGE MODEL FOR CONTROLLABLE GENERATION](https://arxiv.org/pdf/1909.05858.pdf)
- EMNLP2020,[AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts](https://arxiv.org/abs/2010.15980)
- ICML2020,[Discriminative Adversarial Search for Abstractive Summarization](https://arxiv.org/pdf/2002.10375.pdf)
- EMNLP2020,[If Beam Search is the Answer, What was the Question?](https://arxiv.org/pdf/2010.02650.pdf)
- CCOLING2020,[Exploring Controllable Text Generation Techniques](https://arxiv.org/pdf/2005.01822.pdf)
- Arixiv 2021,[FUDGE: Controlled Text Generation With Future Discriminators](https://arxiv.org/pdf/2104.05218.pdf)
- Arixiv 2020,[DEXPERTS: On-the-Fly Controlled Text Generation with Experts and Anti-Experts](https://arxiv.org/pdf/2105.03023.pdf)
- NIPS2020,[Learning to summarize from human feedback](https://arxiv.org/pdf/2009.01325.pdf) 【强化学习】
- ICML2020,[Fine-Tuning Language Models from Human Preferences](https://arxiv.org/pdf/1909.08593.pdf)【强化学习】
- NIPS2019,[Bias Correction of Learned Generative Models using Likelihood-Free Importance Weighting](https://arxiv.org/abs/1906.09531)
- TACL2020,[How Can We Know What Language Models Know?](https://arxiv.org/abs/1911.12543)

# 文本生成（传统）
- 句法结构引导 [Syntax-Guided Controlled Generation of Paraphrases](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00318/96454/Syntax-Guided-Controlled -Generation-of-Paraphrases)

# 文本生成评测
- ACL2020,[BLEURT: Learning Robust Metrics for Text Generation](https://arxiv.org/abs/2004.04696)
- Arixiv 2020, [Evaluation of Text Generation: A Survey](https://arxiv.org/abs/2006.14799)

# date to text
- AAAI2021,[Towards Faithfulness in Open Domain Table-to-text Generation from an Entity-centric View](https://www.aaai.org/AAAI21Papers/AAAI-5176.LiuT.pdf)
- ACL2020, [Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation](https://www.aclweb.org/anthology/2020.acl-main.224.pdf)
- EACL2020,[Does the Order of Training Samples Matter? Improving Neural Data-to-Text Generation with Curriculum Learning](https://arxiv.org/pdf/2102.03554.pdf)



# Story telling
- AAAI2019,[Plan-And-Write: Towards Better Automatic Storytelling](https://arxiv.org/pdf/1811.05701.pdf)
- Arixiv2021,[Plug-and-Blend: A Framework for Controllable Story Generation with Blended Control Codes](https://arxiv.org/pdf/2104.04039.pdf)
- IJCAI2019,[Controllable Neural Story Plot Generation via Reinforcement Learning](https://arxiv.org/abs/1809.10736)  【强化学习】

# style-tranfer
- AAAI2020,[Adapting Language Models for Non-Parallel Author-Stylized Rewriting](https://ojs.aaai.org/index.php/AAAI/article/view/6433)



# 其他
- AAAI 2020, [Fine-grained Recognition: Accounting for Subtle Differences between Similar Classes](https://arxiv.org/pdf/1912.06842.pdf),&[note](./note/2020_10.md)

- NIPS 2019, [Recurrent Space-time Graph Neural Networks](http://papers.nips.cc/paper/9444-recurrent-space-time-graph-neural-networks.pdf),&[note](./note/2020_10.md)

- ICML 2018, [Learning to Reweight Examples for Robust Deep Learning](https://arxiv.org/abs/1803.09050),&[note](./note/2020_10.md)

- ACL.2020,[A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking](https://arxiv.org/abs/2006.01554),&[note](./note/2020_11.md)

- Arixiv 2021, [Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning](https://arxiv.org/pdf/2011.01403.pdf),&[note](./note/2020_11.md)

- ICLR 2021, [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf),&[note](./note/2020_11.md)
- ICML 2020,[Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere](https://arxiv.org/pdf/2005.10242.pdf)

- AAAI 2020, [](),&[note]()
